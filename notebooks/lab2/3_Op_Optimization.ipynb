{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584136b7",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c60e0",
   "metadata": {},
   "source": [
    "# Op Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ece653",
   "metadata": {},
   "source": [
    "Now that our pipeline is working well, let's learn to scale it with multiple GPUs.\n",
    "\n",
    "<b>Learning Objectives</b>:\n",
    "* Learn how to use a LocalCUDACluster to utilize multiple GPUs.\n",
    "* Learn how to [Rename](https://github.com/NVIDIA/NVTabular/blob/main/nvtabular/ops/rename.py) a column.\n",
    "* Learn how to export NVTabular to Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832de61",
   "metadata": {},
   "source": [
    "### 1. NVTabular with Multi-GPU support by LocalCUDACluster\n",
    "\n",
    "So far, we have used the simplest way to apply an NVTabular workflow which utilizes only a single GPU. NVTabular can easily be scaled to multiple GPUs by initializing a [LocalCUDACluster](https://dask-cuda.readthedocs.io/en/latest/ucx.html?highlight=localcudacluster#localcudacluster) first. We will begin by importing all of the libraries we need for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beab0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "\n",
    "import cudf\n",
    "import rmm\n",
    "import nvtabular as nvt\n",
    "import numpy as np\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "from nvtabular.utils import device_mem_size, get_rmm_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbb474",
   "metadata": {},
   "source": [
    "If it is not running already, we highly recommend setting up a terminal on the side to monitor our GPUs with the following command:\n",
    "\n",
    "`watch -n0.1 nvidia-smi --query-gpu=index,memory.used,memory.total,utilization.gpu --format=csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e78caf",
   "metadata": {},
   "source": [
    "With this command, we can see that have 4 GPUs. So far, we've only been using one GPU (`0`), which is using the most memory. The others are barely using anything. Let's put them to work!\n",
    "\n",
    "To do this, we will be using a [LocalCUDACluster](https://dask-cuda.readthedocs.io/en/latest/ucx.html?highlight=localcudacluster#localcudacluster). Here are some of the key parameters:\n",
    "\n",
    "* `protocol`: Protocol to use for communication.\n",
    "  * `tcp` is the default communication.\n",
    "  * `ucx` enables to use NVIDIA's [NVLink](https://www.nvidia.com/en-us/data-center/nvlink/) technology, where GPU's can directly communicate with each other and achieves higher speed-ups. It requires `ucx`, `enable_tcp_over_ucx=True` and `enable_nvlink=True`.\n",
    "* `CUDA_VISIBLE_DEVICES`: Defines visible GPUs devices to the LocalCUDACluster\n",
    " * e.g. `0,1,3` for GPU 0, 1 and 3.\n",
    "* `local_directory`: Defines the directory to buffer data.\n",
    "* `device_memory_limit` : Reduce the memory limit for workers in your cluster. \n",
    "  * This setting may need to be much lower than the actual memory capacity of your device.\n",
    "  \n",
    "Rather than manually entering our memory limit, NVTabular has a number of [utils](https://github.com/NVIDIA/NVTabular/blob/main/nvtabular/utils.py) to help us figure out our capacity programmatically. Let's use 90% of our total capacity. If we use all 100%, there will be no room for anything else, which can lead to memory errors.\n",
    "\n",
    "**TODO**: We've created four variables to use as parameters to `LocalCUDACluster`:\n",
    "* device_memory_limit\n",
    "* temporary_data_directory\n",
    "* protocol\n",
    "* visible_devices\n",
    "\n",
    "Match one of each to the FIXMEs below.\n",
    "\n",
    "**Note**: If you need to rerun this cell, please restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7eb4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33347</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>186.82 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33347' processes=4 threads=4, memory=186.82 GiB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a fraction of capacity to prevent memory errors\n",
    "device_memory_limit = device_mem_size(kind=\"total\") * .9 \n",
    "temporary_data_directory = '/tmp/'\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \"0,1,2,3\"  # Select devices to place workers\n",
    "\n",
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "cluster = LocalCUDACluster(\n",
    "    protocol = protocol,\n",
    "    CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "    local_directory = temporary_data_directory,\n",
    "    device_memory_limit = device_memory_limit\n",
    ")\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5a324d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41978 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41378</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:41978/status' target='_blank'>http://127.0.0.1:41978/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>186.82 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:41378' processes=4 threads=4, memory=186.82 GiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a fraction of capacity to prevent memory errors\n",
    "device_memory_limit = device_mem_size(kind=\"total\") * .9 \n",
    "temporary_data_directory = '/tmp/'\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \"0,1,2,3\"  # Select devices to place workers\n",
    "\n",
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "cluster = LocalCUDACluster(\n",
    "    protocol = protocol,\n",
    "    CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "    local_directory = temporary_data_directory,\n",
    "    device_memory_limit = device_memory_limit\n",
    ")\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ac73e",
   "metadata": {},
   "source": [
    "#### Initializing Memory Pools\n",
    "\n",
    "Since allocating memory is often a performance bottleneck, it is usually a good idea [to initialize](https://docs.rapids.ai/api/rmm/stable/basics.html) a memory pool on each of our workers. When using a distributed cluster, we must use the `client.run` utility to make sure a function is executed on all available workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ec9823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:33810': None,\n",
       " 'tcp://127.0.0.1:37568': None,\n",
       " 'tcp://127.0.0.1:42092': None,\n",
       " 'tcp://127.0.0.1:44123': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RMM pool on ALL workers\n",
    "def _rmm_pool():\n",
    "    rmm.reinitialize()\n",
    "client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0090f0b3",
   "metadata": {},
   "source": [
    "**Done! Congrats, you are using NVTabular with multi-GPU support, now.**\n",
    "\n",
    "That's it. After the LocalCUDACluster is initialized, we can use NVTabular as usual, but it will be executed on multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6088e",
   "metadata": {},
   "source": [
    "### Rename\n",
    "\n",
    "Let's put these GPUs to work with an NVTabular workflow. In our dataset, we have a column called `HourlyWindDirection`. It's in degrees with 0 degree and 360 degrees as true north."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccba965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HourlyWindSpeed_difference_lag_1</th>\n",
       "      <th>HourlyWindDirection</th>\n",
       "      <th>HourlyRelativeHumidity</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyWetBulbTemperature</th>\n",
       "      <th>HourlyWindSpeed_difference_lag_1_filled</th>\n",
       "      <th>HourlyWindDirection_filled</th>\n",
       "      <th>HourlyRelativeHumidity_filled</th>\n",
       "      <th>HourlyDewPointTemperature_filled</th>\n",
       "      <th>HourlyDryBulbTemperature_filled</th>\n",
       "      <th>HourlyWetBulbTemperature_filled</th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.777778</td>\n",
       "      <td>2.047106</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-06-05T12:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.222222</td>\n",
       "      <td>2.106697</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-06-05T13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>-1.528389</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-12-01T01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.777778</td>\n",
       "      <td>2.106697</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-06-05T13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>-1.647572</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-12-01T01:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HourlyWindSpeed_difference_lag_1  HourlyWindDirection  \\\n",
       "0                               1.0                 20.0   \n",
       "1                               0.0                 80.0   \n",
       "2                               0.0                  0.0   \n",
       "3                               5.0                 20.0   \n",
       "4                               0.0                  0.0   \n",
       "\n",
       "   HourlyRelativeHumidity  HourlyDewPointTemperature  \\\n",
       "0                    33.0                  17.777778   \n",
       "1                    29.0                  17.222222   \n",
       "2                    93.0                   2.777778   \n",
       "3                    31.0                  17.777778   \n",
       "4                   100.0                   2.777778   \n",
       "\n",
       "   HourlyDryBulbTemperature  HourlyWetBulbTemperature  \\\n",
       "0                  2.047106                  0.159465   \n",
       "1                  2.106697                  0.159465   \n",
       "2                 -1.528389                  0.159465   \n",
       "3                  2.106697                  0.159465   \n",
       "4                 -1.647572                  0.159465   \n",
       "\n",
       "   HourlyWindSpeed_difference_lag_1_filled  HourlyWindDirection_filled  \\\n",
       "0                                    False                       False   \n",
       "1                                    False                       False   \n",
       "2                                    False                       False   \n",
       "3                                    False                       False   \n",
       "4                                    False                       False   \n",
       "\n",
       "   HourlyRelativeHumidity_filled  HourlyDewPointTemperature_filled  \\\n",
       "0                          False                             False   \n",
       "1                          False                             False   \n",
       "2                          False                             False   \n",
       "3                          False                             False   \n",
       "4                          False                             False   \n",
       "\n",
       "   HourlyDryBulbTemperature_filled  HourlyWetBulbTemperature_filled  \\\n",
       "0                            False                             True   \n",
       "1                            False                             True   \n",
       "2                            False                             True   \n",
       "3                            False                             True   \n",
       "4                            False                             True   \n",
       "\n",
       "       STATION                 DATE  \n",
       "0  72058700184  2011-06-05T12:35:00  \n",
       "1  72058700184  2011-06-05T13:00:00  \n",
       "2  72058700184  2011-12-01T01:00:00  \n",
       "3  72058700184  2011-06-05T13:15:00  \n",
       "4  72058700184  2011-12-01T01:15:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cudf.read_parquet(\"data/transformed_out/*.parquet\")\n",
    "columns = df.columns.to_list()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b2bce",
   "metadata": {},
   "source": [
    "With degrees like this, 350 degrees and 10 degrees seem far away, when physically, they're close. Let's make a pipeline to convert our `HourlyWindDirection` into Latitude and Longitude components.\n",
    "\n",
    "Since our output cannot have two columns with the same name, we will use the [Rename](https://github.com/NVIDIA/NVTabular/blob/main/nvtabular/ops/rename.py) Op to make this possible. We will add a `postfix` to define which output is the latitude component and which output is the longitude component.\n",
    "\n",
    "**TODO**: We've provided an example of `Rename` below for the latitude component. Replace the FIXMEs below to add a `_long` tag to the longitude component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799eb0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lat_speed(col):\n",
    "    return np.cos(np.radians(col))\n",
    "\n",
    "\n",
    "def long_speed(col):\n",
    "    return np.sin(np.radians(col))\n",
    "\n",
    "\n",
    "wind_lat = (\n",
    "    [\"HourlyWindDirection\"]\n",
    "    >> nvt.ops.LambdaOp(lat_speed)\n",
    "    >> nvt.ops.Rename(postfix=\"_lat\")\n",
    ")\n",
    "wind_long = (\n",
    "    [\"HourlyWindDirection\"]\n",
    "    >> nvt.ops.LambdaOp(long_speed)\n",
    "    >> nvt.ops.Rename(postfix=\"_long\")\n",
    ")\n",
    "\n",
    "# Combine all columns\n",
    "all_cols = columns + wind_lat + wind_long\n",
    "\n",
    "# Define workflow\n",
    "files = glob.glob(\"data/transformed_out/*.parquet\")\n",
    "workflow = nvt.Workflow(all_cols)\n",
    "dataset = nvt.Dataset(files, engine=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9724f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lat_speed(col):\n",
    "    return np.cos(np.radians(col))\n",
    "\n",
    "\n",
    "def long_speed(col):\n",
    "    return np.sin(np.radians(col))\n",
    "\n",
    "\n",
    "wind_lat = (\n",
    "    [\"HourlyWindDirection\"]\n",
    "    >> nvt.ops.LambdaOp(lat_speed)\n",
    "    >> nvt.ops.Rename(postfix=\"_lat\")\n",
    ")\n",
    "wind_long = (\n",
    "    [\"HourlyWindDirection\"]\n",
    "    >> nvt.ops.LambdaOp(long_speed)\n",
    "    >> nvt.ops.Rename(postfix=\"_long\")\n",
    ")\n",
    "\n",
    "# Combine all columns\n",
    "all_cols = columns + wind_lat + wind_long\n",
    "\n",
    "# Define workflow\n",
    "files = glob.glob(\"data/transformed_out/*.parquet\")\n",
    "workflow = nvt.Workflow(all_cols)\n",
    "dataset = nvt.Dataset(files, engine=\"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c1777",
   "metadata": {},
   "source": [
    "Let's verify that the pipeline is setup correctly. Confirm the following:\n",
    "* There is a `HourlyWindDirection_lat` column\n",
    "* There is a `HourlyWindDirection_long` column\n",
    "* The above two columns have different values\n",
    "* **All GPUs are used when running the workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c145bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/renamed_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a0d9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HourlyWindDirection_lat</th>\n",
       "      <th>HourlyWindSpeed_difference_lag_1</th>\n",
       "      <th>HourlyWindDirection</th>\n",
       "      <th>HourlyRelativeHumidity</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyWetBulbTemperature</th>\n",
       "      <th>HourlyWindSpeed_difference_lag_1_filled</th>\n",
       "      <th>HourlyWindDirection_filled</th>\n",
       "      <th>HourlyRelativeHumidity_filled</th>\n",
       "      <th>HourlyDewPointTemperature_filled</th>\n",
       "      <th>HourlyDryBulbTemperature_filled</th>\n",
       "      <th>HourlyWetBulbTemperature_filled</th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyWindDirection_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>17.222222</td>\n",
       "      <td>0.259358</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2013-09-25T21:55:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.736091</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2012-08-09T05:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>0.616908</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2012-06-10T01:15:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>26.111111</td>\n",
       "      <td>1.570373</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2012-09-04T16:15:00</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>26.111111</td>\n",
       "      <td>0.855274</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-08-23T01:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HourlyWindDirection_lat  HourlyWindSpeed_difference_lag_1  \\\n",
       "0                      1.0                              -3.0   \n",
       "1                      1.0                               0.0   \n",
       "2                      1.0                               0.0   \n",
       "3                     -0.5                               0.0   \n",
       "4                      1.0                               0.0   \n",
       "\n",
       "   HourlyWindDirection  HourlyRelativeHumidity  HourlyDewPointTemperature  \\\n",
       "0                  0.0                    84.0                  17.222222   \n",
       "1                  0.0                   100.0                  25.000000   \n",
       "2                  0.0                   100.0                  23.888889   \n",
       "3                240.0                    67.0                  26.111111   \n",
       "4                  0.0                   100.0                  26.111111   \n",
       "\n",
       "   HourlyDryBulbTemperature  HourlyWetBulbTemperature  \\\n",
       "0                  0.259358                  0.159465   \n",
       "1                  0.736091                  0.159465   \n",
       "2                  0.616908                  0.159465   \n",
       "3                  1.570373                  0.159465   \n",
       "4                  0.855274                  0.159465   \n",
       "\n",
       "   HourlyWindSpeed_difference_lag_1_filled  HourlyWindDirection_filled  \\\n",
       "0                                    False                       False   \n",
       "1                                    False                       False   \n",
       "2                                    False                       False   \n",
       "3                                    False                       False   \n",
       "4                                    False                       False   \n",
       "\n",
       "   HourlyRelativeHumidity_filled  HourlyDewPointTemperature_filled  \\\n",
       "0                          False                             False   \n",
       "1                          False                             False   \n",
       "2                          False                             False   \n",
       "3                          False                             False   \n",
       "4                          False                             False   \n",
       "\n",
       "   HourlyDryBulbTemperature_filled  HourlyWetBulbTemperature_filled  \\\n",
       "0                            False                             True   \n",
       "1                            False                             True   \n",
       "2                            False                             True   \n",
       "3                            False                             True   \n",
       "4                            False                             True   \n",
       "\n",
       "       STATION                 DATE  HourlyWindDirection_long  \n",
       "0  72058700184  2013-09-25T21:55:00                  0.000000  \n",
       "1  72058700184  2012-08-09T05:00:00                  0.000000  \n",
       "2  72058700184  2012-06-10T01:15:00                  0.000000  \n",
       "3  72058700184  2012-09-04T16:15:00                 -0.866025  \n",
       "4  72058700184  2011-08-23T01:00:00                  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.transform(dataset).to_parquet(\n",
    "    output_path=\"data/renamed_out/\", out_files_per_proc=4\n",
    ")\n",
    "df_out = cudf.read_parquet(\"data/renamed_out/*.parquet\")\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab52db",
   "metadata": {},
   "source": [
    "Congratulations, all done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35f66e",
   "metadata": {},
   "source": [
    "In order to shut down our LocalCUDACluster, we can use the `close` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "185bc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5c813",
   "metadata": {},
   "source": [
    "### Dask Integration and Other Tools\n",
    "\n",
    "NVTabular is tightly integrated with [Dask-CuDF](https://github.com/rapidsai/dask-cudf), and we can convert a NVTabular Dataset to a Dask DataFrame. While we're at it, let's take a closer look at [NVTabular datasets](https://nvidia-merlin.github.io/NVTabular/main/api/dataset.html#).\n",
    "\n",
    "`??nvt.Dataset`\n",
    "\n",
    "```\n",
    " Parameters\n",
    "    -----------\n",
    "    path_or_source : str, list of str, or <dask.dataframe|cudf|pd>.DataFrame\n",
    "        Dataset path (or list of paths), or a DataFrame. If string,\n",
    "        should specify a specific file or directory path. If this is a\n",
    "        directory path, the directory structure must be flat (nested\n",
    "        directories are not yet supported).\n",
    "    engine : str or DatasetEngine\n",
    "        DatasetEngine object or string identifier of engine. Current\n",
    "        string options include: (\"parquet\", \"csv\", \"avro\"). This argument\n",
    "        is ignored if path_or_source is a DataFrame type.\n",
    "    part_size : str or int\n",
    "        Desired size (in bytes) of each Dask partition.\n",
    "        If None, part_mem_fraction will be used to calculate the\n",
    "        partition size.  Note that the underlying engine may allow\n",
    "        other custom kwargs to override this argument. This argument\n",
    "        is ignored if path_or_source is a DataFrame type.\n",
    "    part_mem_fraction : float (default 0.125)\n",
    "        Fractional size of desired Dask partitions (relative\n",
    "        to GPU memory capacity). Ignored if part_size is passed\n",
    "        directly. Note that the underlying engine may allow other\n",
    "        custom kwargs to override this argument. This argument\n",
    "        is ignored if path_or_source is a DataFrame type.\n",
    "    storage_options: None or dict\n",
    "        Further parameters to pass to the bytes backend. This argument\n",
    "        is ignored if path_or_source is a DataFrame type.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92287ef1",
   "metadata": {},
   "source": [
    "First, `path_or_source` defines our dataset source. For example, we can directly initialize a `nvt.Dataset` from a dask.dataframe.DataFrame or cudf.DataFrame, as below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f576b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates 1 partition\n",
    "df = cudf.DataFrame({'col1': [0,1,2,3,4], 'col2': ['a', 'b', 'c', 'd', 'e']})\n",
    "dataset = nvt.Dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af33ef",
   "metadata": {},
   "source": [
    "If we read data from disk, `path_or_source` is a string or list of strings for dataset path. The parameter `engine` defines the filetype and nvt.Dataset supports `parquet`, `csv` and `avro` file formats.\n",
    "\n",
    "**The parameters `part_size` or `part_mem_fraction` are important when we read data from disk. They define the size of the chunks we read in memory.** \n",
    "\n",
    "Only one of the parameters is used. If `part_size` is defined, then `part_mem_fraction` is ignored. By default, both parquet and csv-based data will be converted to a Dask-DataFrame collection with a maximum partition size of roughly 12.5 percent of the total memory on a single device.  The partition size can be changed to a different fraction of total memory on a single device with the `part_mem_fraction` argument.\n",
    "\n",
    "* `part_size` defines the size of each Dask partition in bytes. A good rule of thumb is `128MB` or `256MB`.\n",
    "* `part_mem_fraction` defines fractional size of desired Dask partitions relative to GPU memory.\n",
    "\n",
    "Example:\n",
    "* if `part_size='100MB'`, then each Dask partition is of 100MB (or smaller)\n",
    "* if `part_mem_fraction=0.1`, then 10% of the single GPU memory (or smaller) is used for the Dask partitions\n",
    "\n",
    "**TODO**: Use [glob](https://docs.python.org/3/library/glob.html) to find all of the `.parquet` files in either `data/parquet_out`, `data/renamed_out`, `data/transformed_out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6da3747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/*/*.parquet\", recursive=True)\n",
    "dataset = nvt.Dataset(files, engine='parquet', part_size='128MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba23cd",
   "metadata": {},
   "source": [
    "We can then convert this dataset to a Dask DataFrame using `to_ddf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e416a32f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KilledWorker",
     "evalue": "('gen-metadata-353e181cb2579e66473c0592d435ed0a', <Worker 'tcp://127.0.0.1:46440', name: 2, memory: 0, processing: 1>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a94068f04e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_ddf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mddf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/nvtabular/io/dataset.py\u001b[0m in \u001b[0;36mto_ddf\u001b[0;34m(self, columns, shuffle, seed)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \"\"\"\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# Use DatasetEngine to create ddf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mddf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_ddf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# Shuffle the partitions of ddf (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/nvtabular/io/parquet.py\u001b[0m in \u001b[0;36mto_ddf\u001b[0;34m(self, columns, cpu)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mgather_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0msplit_row_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_groups_per_part\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         )\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/dask_cudf/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, split_row_groups, row_groups_per_part, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0msplit_row_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_row_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCudfEngine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/io/parquet/core.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, engine, gather_statistics, split_row_groups, read_from_paths, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0msplit_row_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_row_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mread_from_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_from_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     )\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/dask_cudf/io/parquet.py\u001b[0m in \u001b[0;36mread_metadata\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrowEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# If `strings_to_categorical==True`, convert objects to int32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/io/parquet/arrow.py\u001b[0m in \u001b[0;36mread_metadata\u001b[0;34m(cls, fs, paths, categories, index, gather_statistics, filters, split_row_groups, read_from_paths, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/io/parquet/arrow.py\u001b[0m in \u001b[0;36m_gather_metadata\u001b[0;34m(cls, paths, fs, split_row_groups, gather_statistics, filters, index, dataset_kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m                     \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                     \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m                     \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m                 )\n\u001b[1;32m   1789\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/dask/dataframe/io/parquet/core.py\u001b[0m in \u001b[0;36mcreate_metadata_file\u001b[0;34m(paths, root_dir, out_dir, engine, storage_options, split_every, compute, compute_kwargs, fs)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0mcompute_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcompute_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1979\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m             )\n\u001b[1;32m   1983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             return sync(\n\u001b[0;32m--> 844\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m             )\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKilledWorker\u001b[0m: ('gen-metadata-353e181cb2579e66473c0592d435ed0a', <Worker 'tcp://127.0.0.1:46440', name: 2, memory: 0, processing: 1>)"
     ]
    }
   ],
   "source": [
    "ddf = dataset.to_ddf()\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344944e",
   "metadata": {},
   "source": [
    "We can check the memory usage per columns with [memory_usage](https://docs.rapids.ai/api/cudf/legacy/api.html#cudf.core.dataframe.DataFrame.memory_usage) and `memory_usage_per_partition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7572058",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-301f942032ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ddf' is not defined"
     ]
    }
   ],
   "source": [
    "ddf.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acc96bae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-555c64edc78b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage_per_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ddf' is not defined"
     ]
    }
   ],
   "source": [
    "ddf.memory_usage_per_partition()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c815dce",
   "metadata": {},
   "source": [
    "However, since Dask is lazy, and nothing is computed yet, we're only given information about the graph nodes. To force a result, we can use `compute`. The memory usage is in bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac7fae77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e44801855e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ddf' is not defined"
     ]
    }
   ],
   "source": [
    "ddf.memory_usage().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588ab6a",
   "metadata": {},
   "source": [
    "Congratulations on getting through this set of courses! If you would like to learn more about NVTabular and tools for Retail Big Data, these notebooks were created with help from the [NVIDIA Merlin](https://developer.nvidia.com/nvidia-merlin) team. Merlin is a framework used to handle industry scale Recommender Systems.\n",
    "\n",
    "There are four main components:\n",
    "\n",
    "<center><img src='https://developer.nvidia.com/sites/default/files/akamai/merlin/recommender-systems-dev-web-850.svg' width='80%'></center>\n",
    "\n",
    "* [NVTabular](https://nvidia-merlin.github.io/NVTabular/main/Introduction.html): Feature engineering and preprocessing library designed to quickly and easily manipulate terabytes of tabular data\n",
    "* NVTabular dataloader: Highly optimized dataloaders to accelerate TensorFlow and PyTorch pipelines\n",
    "* [HugeCTR](https://github.com/NVIDIA/HugeCTR): Highly efficient Python and C++ GPU framework and reference design dedicated for recommendation workload training\n",
    "* [Triton](https://developer.nvidia.com/nvidia-triton-inference-server): Production inference on GPUs for feature transforms and neural network execution.\n",
    "\n",
    "See you in the next lab!\n",
    "\n",
    "If you would like to see the GPU numbers drop to zero one more time, feel free to fun the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68a94252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e5309",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
